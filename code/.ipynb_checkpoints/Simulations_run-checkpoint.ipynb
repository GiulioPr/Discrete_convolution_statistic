{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quanti/Desktop/Convolution_statistic/Discrete_convolution_statistic/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as sps\n",
    "import scipy.special as spsp\n",
    "import scipy.linalg as spl\n",
    "from functools import reduce\n",
    "import discrete_convolution_statistics as dcs\n",
    "import pandas as pd\n",
    "\n",
    "path_proj = os.path.dirname(os.getcwd())+ '/'\n",
    "path_csv = path_proj + 'csv/'\n",
    "path_plot = path_proj + 'figures/'\n",
    "\n",
    "print(path_proj)\n",
    "\n",
    "#PARAMETERS\n",
    "#Number of model simulations\n",
    "n_repeats = 100000\n",
    "#Level of significance\n",
    "alpha = 0.05\n",
    "#Ranks to be tested/degrees of freedom, for the convolution statistics\n",
    "ranks = np.array([1, 2], dtype=int)\n",
    "#Set seed for the random number generator\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_dist(n, a, b):\n",
    "    return np.asarray([spsp.binom(n,k) * spsp.beta(k+a,n-k+b) / spsp.beta(a,b)\n",
    "                        for k in range(int(n)+1)])\n",
    "\n",
    "def bb_rho1(n, p):\n",
    "    res = np.zeros(n+1)\n",
    "    res[0] = 1.-p\n",
    "    res[-1] = p\n",
    "    return res\n",
    "    \n",
    "def bb_rho0(n, p):\n",
    "    return np.asarray([spsp.binom(n, k) * p**(k) * (1.-p)**(n-k)\n",
    "                        for k in range(n+1)])\n",
    "            \n",
    "def BB_pmf(n, p, rho):\n",
    "    if rho == 0.:\n",
    "        return bb_rho0(n, p)\n",
    "    elif rho == 1.:\n",
    "        return bb_rho1(n, p)\n",
    "    else:\n",
    "        a = p * (1.-rho)/rho\n",
    "        b = (1.-p) * (1.-rho)/rho\n",
    "        return bb_dist(n, a, b)\n",
    "\n",
    "def mixBe_pmf(p, q, rho):\n",
    "    p2 = p * q + np.sqrt(p*(1.-p) * q*(1.-q))\n",
    "    pmf_1 = np.array([1.-p2, 0., p2])\n",
    "    pmf_1 = pmf_1/sum(pmf_1)\n",
    "    return np.convolve(BB_pmf(1, p, 0.), BB_pmf(1, q, 0.)) * (1.-rho) + (rho * pmf_1)\n",
    "\n",
    "def draw_multinomials(nn, x_lst):\n",
    "    return np.array([np.random.multinomial(nn[k], x_lst[k]) for k in range(len(x_lst))])\n",
    "\n",
    "def count_of_sum(cnt_x, support, min_nx):\n",
    "    if min_nx == 0:\n",
    "        return np.zeros(len(support))\n",
    "    else:\n",
    "        obs = np.zeros(min_nx)\n",
    "        for k in range(len(cnt_x)):\n",
    "            temp_obs = np.hstack([np.ones(cnt_x[k,i])*i for i in range(len(cnt_x[k]))])\n",
    "            obs = obs + np.random.choice(temp_obs, size=min_nx, replace=False)\n",
    "        obs_support, counts = np.unique(obs, return_counts=True)    \n",
    "        return np.hstack([counts[obs_support==k] if any(obs_support==k) else np.zeros(1, dtype=int)\n",
    "                          for k in support])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run one simulation of the model X_1 + X_2 and Y, having\n",
    "#X_1~Be(p) with sample size nn[0], X_2~Be(q) with sample size nn[1],\n",
    "#and Y~Be(p)+Be(q) with sample size nn[2] where Be(p), Be(q) are correlated via rho.\n",
    "#Hypotheses of goodness-of-fit (gof) X_1 + X_2 ~ z and equality in distribution (ed) X_1 + X_2 ~ Y\n",
    "#are tested using these statistics: Pearson's, Convolution, and\n",
    "#Convolution using true covariance matrix instead of being estimated.\n",
    "#For the Convolution statistics, the degrees of freedom/covariance matrix in ranks are assayed.\n",
    "#'run_simulations' output is the proportion of rejections from these statistics,\n",
    "#approximated via Monte Carlo method repeating the experiment n_repeats times.\n",
    "#If filename_pval_dist differs from '', then the n_repeats p-values, from each of the statistics above,\n",
    "#are exported into a csv file, named after filename_pval_dist.\n",
    "def run_simulations(p, q, rho, ranks, nn, alpha, n_repeats, filename_pval_dist=''):\n",
    "    \n",
    "    #Determine true distributions of X_i and Y_i and Z\n",
    "    lst_prob = [p, q]\n",
    "    x_lst = [BB_pmf(1, p, 0.) for p in lst_prob]\n",
    "    y_lst = [mixBe_pmf(p, q, rho)]\n",
    "    z = reduce(np.convolve, y_lst)\n",
    "    \n",
    "    #Minimum samples' size, assumed to be among the X_i for this model\n",
    "    mm = min(nn)\n",
    "    \n",
    "    #Simulations\n",
    "    counts_x = np.array([draw_multinomials(nn[:len(x_lst)], x_lst) for once in range(n_repeats)])\n",
    "    counts_y = np.array([draw_multinomials(nn[-len(y_lst):], y_lst) for once in range(n_repeats)])\n",
    "\n",
    "    #Determine true covariance matrices\n",
    "    gofSig = dcs.conv_covar(x_lst, mm/nn[:len(x_lst)])\n",
    "    if len(y_lst) > 1:\n",
    "        edSig = gofSig + dcs.conv_covar(y_lst, mm/nn[-len(y_lst):])\n",
    "    else:\n",
    "        edSig = gofSig + dcs.mult_cov(y_lst[0])*mm/nn[-1]\n",
    "    \n",
    "    #Truncate simulations and sum variables into X_1 + X_2\n",
    "    min_nx = min([cnt_x.sum() for cnt_x in counts_x[0]])\n",
    "    counts_sum_x = np.array([count_of_sum(cnt_x, np.arange(len(z)), min_nx)\n",
    "                             for cnt_x in counts_x])\n",
    "    #There is only one Y variable in this model, so summing is not necessary\n",
    "    counts_sum_y = np.array([oy[0] for oy in counts_y])\n",
    "\n",
    "    #Chi2 test (fixed rank)\n",
    "    gof_chi2 = np.array([dcs.chi2_gof(trc_ob, min_nx*z) for trc_ob in counts_sum_x])\n",
    "    ed_chi2 = np.array([dcs.chi2_ed(np.array([ox, oy])) for ox,oy in zip(counts_sum_x, counts_sum_y)])\n",
    "\n",
    "    gof_conv = {}\n",
    "    ed_conv = {}\n",
    "    gof_true = {}\n",
    "    ed_true = {}\n",
    "    for rk in ranks:\n",
    "        #Conv test\n",
    "        gof_conv[rk] = np.array(list(\n",
    "            map(lambda ox: dcs.conv_test(ary_obsx=ox, gof_z=z,\n",
    "                                         rk=rk, bool_force_rank=True),\n",
    "                counts_x)\n",
    "        ))\n",
    "        ed_conv[rk] = np.array(list(\n",
    "            map(lambda ox,oy: dcs.conv_test(ary_obsx=ox, ary_obsy=oy,\n",
    "                                            rk=rk, bool_force_rank=True),\n",
    "                counts_x, counts_y)\n",
    "        ))\n",
    "\n",
    "        #True sigma conv test\n",
    "        gof_true[rk] = np.array(list(\n",
    "            map(lambda ox: dcs.conv_test_true_S(sigma=gofSig, ary_obsx=ox, gof_z=z,\n",
    "                                                rk=rk, bool_force_rank=True),\n",
    "                counts_x)\n",
    "        ))\n",
    "        ed_true[rk] = np.array(list(\n",
    "            map(lambda ox,oy: dcs.conv_test_true_S(sigma=edSig, ary_obsx=ox, ary_obsy=oy,\n",
    "                                                   rk=rk, bool_force_rank=True),\n",
    "                counts_x, counts_y)\n",
    "        ))\n",
    "        \n",
    "    if filename_pval_dist != '':\n",
    "        dct_pear = {'Pearson_gof':gof_chi2[:,1], 'Pearson_ed':ed_chi2[:,1]}\n",
    "        dct_conv_gof = {'Conv_gof_'+str(rk):gof_conv[rk][:,1] for rk in ranks}\n",
    "        dct_conv_ed = {'Conv_ed_'+str(rk):ed_conv[rk][:,1] for rk in ranks}\n",
    "        dct_true_gof = {'True_gof_'+str(rk):gof_true[rk][:,1] for rk in ranks}\n",
    "        dct_true_ed = {'True_ed_'+str(rk):ed_true[rk][:,1] for rk in ranks}\n",
    "        df = pd.DataFrame({**dct_pear, **dct_conv_gof, **dct_conv_ed, **dct_true_gof, **dct_true_ed})     \n",
    "        df.to_csv(filename_pval_dist, index=False)\n",
    "        \n",
    "    #Proportions of rejection (por)\n",
    "    por_gof_Pearson = (gof_chi2[:,1] < alpha).sum() / n_repeats\n",
    "    por_ed_Pearson = (ed_chi2[:,1] < alpha).sum() / n_repeats\n",
    "    por_gof_conv = np.array([(gof_conv[rk][:,1] < alpha).sum() / n_repeats for rk in ranks])\n",
    "    por_ed_conv = np.array([(ed_conv[rk][:,1] < alpha).sum() / n_repeats for rk in ranks])\n",
    "    por_gof_true = np.array([(gof_true[rk][:,1] < alpha).sum() / n_repeats for rk in ranks])\n",
    "    por_ed_true = np.array([(ed_true[rk][:,1] < alpha).sum() / n_repeats for rk in ranks])\n",
    "    return np.hstack(((por_gof_Pearson, por_ed_Pearson),\n",
    "                      por_gof_conv, por_ed_conv, por_gof_true, por_ed_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = [10. 10. 10.] p = 0.3 q = 0.8\n",
      "ALL X_i PASS THE RULE-OF-THUMB: True\n",
      "Z PASSES THE RULE-OF-THUMB: True \n",
      "\n",
      "n = [10. 20. 20.] p = 0.3 q = 0.8\n",
      "ALL X_i PASS THE RULE-OF-THUMB: True\n",
      "Z PASSES THE RULE-OF-THUMB: True \n",
      "\n",
      "n = [100. 100. 100.] p = 0.3 q = 0.8\n",
      "ALL X_i PASS THE RULE-OF-THUMB: True\n",
      "Z PASSES THE RULE-OF-THUMB: True \n",
      "\n",
      "n = [10. 10. 10.] p = 0.1 q = 0.9\n",
      "ALL X_i PASS THE RULE-OF-THUMB: False\n",
      "Z PASSES THE RULE-OF-THUMB: False \n",
      "\n",
      "n = [10. 20. 20.] p = 0.1 q = 0.9\n",
      "ALL X_i PASS THE RULE-OF-THUMB: False\n",
      "Z PASSES THE RULE-OF-THUMB: False \n",
      "\n",
      "n = [100. 100. 100.] p = 0.1 q = 0.9\n",
      "ALL X_i PASS THE RULE-OF-THUMB: True\n",
      "Z PASSES THE RULE-OF-THUMB: True \n",
      "\n",
      "[10. 10. 10.] (0.3, 0.8) 0.0 1\n",
      "[10. 10. 10.] (0.3, 0.8) 0.01 2\n",
      "[10. 10. 10.] (0.3, 0.8) 0.02 3\n",
      "[10. 10. 10.] (0.3, 0.8) 0.03 4\n",
      "[10. 10. 10.] (0.3, 0.8) 0.04 5\n",
      "[10. 10. 10.] (0.3, 0.8) 0.05 6\n",
      "[10. 10. 10.] (0.3, 0.8) 0.06 7\n",
      "[10. 10. 10.] (0.3, 0.8) 0.07 8\n",
      "[10. 10. 10.] (0.3, 0.8) 0.08 9\n",
      "[10. 10. 10.] (0.3, 0.8) 0.09 10\n",
      "[10. 10. 10.] (0.3, 0.8) 0.1 11\n",
      "[10. 10. 10.] (0.3, 0.8) 0.11 12\n",
      "[10. 10. 10.] (0.3, 0.8) 0.12 13\n",
      "[10. 10. 10.] (0.3, 0.8) 0.13 14\n",
      "[10. 10. 10.] (0.3, 0.8) 0.14 15\n",
      "[10. 10. 10.] (0.3, 0.8) 0.15 16\n",
      "[10. 10. 10.] (0.3, 0.8) 0.16 17\n",
      "[10. 10. 10.] (0.3, 0.8) 0.17 18\n",
      "[10. 10. 10.] (0.3, 0.8) 0.18 19\n",
      "[10. 10. 10.] (0.3, 0.8) 0.19 20\n",
      "[10. 10. 10.] (0.3, 0.8) 0.2 21\n",
      "[10. 10. 10.] (0.3, 0.8) 0.21 22\n",
      "[10. 10. 10.] (0.3, 0.8) 0.22 23\n",
      "[10. 10. 10.] (0.3, 0.8) 0.23 24\n",
      "[10. 10. 10.] (0.3, 0.8) 0.24 25\n",
      "[10. 10. 10.] (0.3, 0.8) 0.25 26\n",
      "[10. 10. 10.] (0.3, 0.8) 0.26 27\n",
      "[10. 10. 10.] (0.3, 0.8) 0.27 28\n",
      "[10. 10. 10.] (0.3, 0.8) 0.28 29\n",
      "[10. 10. 10.] (0.3, 0.8) 0.29 30\n",
      "[10. 10. 10.] (0.3, 0.8) 0.3 31\n",
      "[10. 10. 10.] (0.3, 0.8) 0.31 32\n",
      "[10. 10. 10.] (0.3, 0.8) 0.32 33\n",
      "[10. 10. 10.] (0.3, 0.8) 0.33 34\n",
      "[10. 10. 10.] (0.3, 0.8) 0.34 35\n",
      "[10. 10. 10.] (0.3, 0.8) 0.35000000000000003 36\n",
      "[10. 10. 10.] (0.3, 0.8) 0.36 37\n",
      "[10. 10. 10.] (0.3, 0.8) 0.37 38\n",
      "[10. 10. 10.] (0.3, 0.8) 0.38 39\n",
      "[10. 10. 10.] (0.3, 0.8) 0.39 40\n",
      "[10. 10. 10.] (0.1, 0.9) 0.0 41\n",
      "[10. 10. 10.] (0.1, 0.9) 0.01 42\n",
      "[10. 10. 10.] (0.1, 0.9) 0.02 43\n",
      "[10. 10. 10.] (0.1, 0.9) 0.03 44\n",
      "[10. 10. 10.] (0.1, 0.9) 0.04 45\n",
      "[10. 10. 10.] (0.1, 0.9) 0.05 46\n",
      "[10. 10. 10.] (0.1, 0.9) 0.06 47\n",
      "[10. 10. 10.] (0.1, 0.9) 0.07 48\n",
      "[10. 10. 10.] (0.1, 0.9) 0.08 49\n",
      "[10. 10. 10.] (0.1, 0.9) 0.09 50\n",
      "[10. 10. 10.] (0.1, 0.9) 0.1 51\n",
      "[10. 10. 10.] (0.1, 0.9) 0.11 52\n",
      "[10. 10. 10.] (0.1, 0.9) 0.12 53\n",
      "[10. 10. 10.] (0.1, 0.9) 0.13 54\n",
      "[10. 10. 10.] (0.1, 0.9) 0.14 55\n",
      "[10. 10. 10.] (0.1, 0.9) 0.15 56\n",
      "[10. 10. 10.] (0.1, 0.9) 0.16 57\n",
      "[10. 10. 10.] (0.1, 0.9) 0.17 58\n",
      "[10. 10. 10.] (0.1, 0.9) 0.18 59\n",
      "[10. 10. 10.] (0.1, 0.9) 0.19 60\n",
      "[10. 10. 10.] (0.1, 0.9) 0.2 61\n",
      "[10. 10. 10.] (0.1, 0.9) 0.21 62\n",
      "[10. 10. 10.] (0.1, 0.9) 0.22 63\n",
      "[10. 10. 10.] (0.1, 0.9) 0.23 64\n",
      "[10. 10. 10.] (0.1, 0.9) 0.24 65\n",
      "[10. 10. 10.] (0.1, 0.9) 0.25 66\n",
      "[10. 10. 10.] (0.1, 0.9) 0.26 67\n",
      "[10. 10. 10.] (0.1, 0.9) 0.27 68\n",
      "[10. 10. 10.] (0.1, 0.9) 0.28 69\n",
      "[10. 10. 10.] (0.1, 0.9) 0.29 70\n",
      "[10. 10. 10.] (0.1, 0.9) 0.3 71\n",
      "[10. 10. 10.] (0.1, 0.9) 0.31 72\n",
      "[10. 10. 10.] (0.1, 0.9) 0.32 73\n",
      "[10. 10. 10.] (0.1, 0.9) 0.33 74\n",
      "[10. 10. 10.] (0.1, 0.9) 0.34 75\n",
      "[10. 10. 10.] (0.1, 0.9) 0.35000000000000003 76\n",
      "[10. 10. 10.] (0.1, 0.9) 0.36 77\n",
      "[10. 10. 10.] (0.1, 0.9) 0.37 78\n",
      "[10. 10. 10.] (0.1, 0.9) 0.38 79\n",
      "[10. 10. 10.] (0.1, 0.9) 0.39 80\n",
      "[10. 20. 20.] (0.3, 0.8) 0.0 81\n",
      "[10. 20. 20.] (0.3, 0.8) 0.01 82\n",
      "[10. 20. 20.] (0.3, 0.8) 0.02 83\n",
      "[10. 20. 20.] (0.3, 0.8) 0.03 84\n",
      "[10. 20. 20.] (0.3, 0.8) 0.04 85\n",
      "[10. 20. 20.] (0.3, 0.8) 0.05 86\n",
      "[10. 20. 20.] (0.3, 0.8) 0.06 87\n",
      "[10. 20. 20.] (0.3, 0.8) 0.07 88\n",
      "[10. 20. 20.] (0.3, 0.8) 0.08 89\n",
      "[10. 20. 20.] (0.3, 0.8) 0.09 90\n",
      "[10. 20. 20.] (0.3, 0.8) 0.1 91\n",
      "[10. 20. 20.] (0.3, 0.8) 0.11 92\n",
      "[10. 20. 20.] (0.3, 0.8) 0.12 93\n",
      "[10. 20. 20.] (0.3, 0.8) 0.13 94\n",
      "[10. 20. 20.] (0.3, 0.8) 0.14 95\n",
      "[10. 20. 20.] (0.3, 0.8) 0.15 96\n",
      "[10. 20. 20.] (0.3, 0.8) 0.16 97\n",
      "[10. 20. 20.] (0.3, 0.8) 0.17 98\n",
      "[10. 20. 20.] (0.3, 0.8) 0.18 99\n",
      "[10. 20. 20.] (0.3, 0.8) 0.19 100\n",
      "[10. 20. 20.] (0.3, 0.8) 0.2 101\n",
      "[10. 20. 20.] (0.3, 0.8) 0.21 102\n",
      "[10. 20. 20.] (0.3, 0.8) 0.22 103\n",
      "[10. 20. 20.] (0.3, 0.8) 0.23 104\n",
      "[10. 20. 20.] (0.3, 0.8) 0.24 105\n",
      "[10. 20. 20.] (0.3, 0.8) 0.25 106\n",
      "[10. 20. 20.] (0.3, 0.8) 0.26 107\n",
      "[10. 20. 20.] (0.3, 0.8) 0.27 108\n",
      "[10. 20. 20.] (0.3, 0.8) 0.28 109\n",
      "[10. 20. 20.] (0.3, 0.8) 0.29 110\n",
      "[10. 20. 20.] (0.3, 0.8) 0.3 111\n",
      "[10. 20. 20.] (0.3, 0.8) 0.31 112\n",
      "[10. 20. 20.] (0.3, 0.8) 0.32 113\n",
      "[10. 20. 20.] (0.3, 0.8) 0.33 114\n",
      "[10. 20. 20.] (0.3, 0.8) 0.34 115\n",
      "[10. 20. 20.] (0.3, 0.8) 0.35000000000000003 116\n",
      "[10. 20. 20.] (0.3, 0.8) 0.36 117\n",
      "[10. 20. 20.] (0.3, 0.8) 0.37 118\n",
      "[10. 20. 20.] (0.3, 0.8) 0.38 119\n",
      "[10. 20. 20.] (0.3, 0.8) 0.39 120\n",
      "[10. 20. 20.] (0.1, 0.9) 0.0 121\n",
      "[10. 20. 20.] (0.1, 0.9) 0.01 122\n",
      "[10. 20. 20.] (0.1, 0.9) 0.02 123\n",
      "[10. 20. 20.] (0.1, 0.9) 0.03 124\n",
      "[10. 20. 20.] (0.1, 0.9) 0.04 125\n",
      "[10. 20. 20.] (0.1, 0.9) 0.05 126\n",
      "[10. 20. 20.] (0.1, 0.9) 0.06 127\n",
      "[10. 20. 20.] (0.1, 0.9) 0.07 128\n",
      "[10. 20. 20.] (0.1, 0.9) 0.08 129\n",
      "[10. 20. 20.] (0.1, 0.9) 0.09 130\n",
      "[10. 20. 20.] (0.1, 0.9) 0.1 131\n",
      "[10. 20. 20.] (0.1, 0.9) 0.11 132\n",
      "[10. 20. 20.] (0.1, 0.9) 0.12 133\n",
      "[10. 20. 20.] (0.1, 0.9) 0.13 134\n",
      "[10. 20. 20.] (0.1, 0.9) 0.14 135\n",
      "[10. 20. 20.] (0.1, 0.9) 0.15 136\n",
      "[10. 20. 20.] (0.1, 0.9) 0.16 137\n",
      "[10. 20. 20.] (0.1, 0.9) 0.17 138\n",
      "[10. 20. 20.] (0.1, 0.9) 0.18 139\n",
      "[10. 20. 20.] (0.1, 0.9) 0.19 140\n",
      "[10. 20. 20.] (0.1, 0.9) 0.2 141\n",
      "[10. 20. 20.] (0.1, 0.9) 0.21 142\n",
      "[10. 20. 20.] (0.1, 0.9) 0.22 143\n",
      "[10. 20. 20.] (0.1, 0.9) 0.23 144\n",
      "[10. 20. 20.] (0.1, 0.9) 0.24 145\n",
      "[10. 20. 20.] (0.1, 0.9) 0.25 146\n",
      "[10. 20. 20.] (0.1, 0.9) 0.26 147\n",
      "[10. 20. 20.] (0.1, 0.9) 0.27 148\n",
      "[10. 20. 20.] (0.1, 0.9) 0.28 149\n",
      "[10. 20. 20.] (0.1, 0.9) 0.29 150\n",
      "[10. 20. 20.] (0.1, 0.9) 0.3 151\n",
      "[10. 20. 20.] (0.1, 0.9) 0.31 152\n",
      "[10. 20. 20.] (0.1, 0.9) 0.32 153\n",
      "[10. 20. 20.] (0.1, 0.9) 0.33 154\n",
      "[10. 20. 20.] (0.1, 0.9) 0.34 155\n",
      "[10. 20. 20.] (0.1, 0.9) 0.35000000000000003 156\n",
      "[10. 20. 20.] (0.1, 0.9) 0.36 157\n",
      "[10. 20. 20.] (0.1, 0.9) 0.37 158\n",
      "[10. 20. 20.] (0.1, 0.9) 0.38 159\n",
      "[10. 20. 20.] (0.1, 0.9) 0.39 160\n",
      "[100. 100. 100.] (0.3, 0.8) 0.0 161\n",
      "[100. 100. 100.] (0.3, 0.8) 0.01 162\n",
      "[100. 100. 100.] (0.3, 0.8) 0.02 163\n",
      "[100. 100. 100.] (0.3, 0.8) 0.03 164\n",
      "[100. 100. 100.] (0.3, 0.8) 0.04 165\n",
      "[100. 100. 100.] (0.3, 0.8) 0.05 166\n",
      "[100. 100. 100.] (0.3, 0.8) 0.06 167\n",
      "[100. 100. 100.] (0.3, 0.8) 0.07 168\n",
      "[100. 100. 100.] (0.3, 0.8) 0.08 169\n",
      "[100. 100. 100.] (0.3, 0.8) 0.09 170\n",
      "[100. 100. 100.] (0.3, 0.8) 0.1 171\n",
      "[100. 100. 100.] (0.3, 0.8) 0.11 172\n",
      "[100. 100. 100.] (0.3, 0.8) 0.12 173\n",
      "[100. 100. 100.] (0.3, 0.8) 0.13 174\n",
      "[100. 100. 100.] (0.3, 0.8) 0.14 175\n",
      "[100. 100. 100.] (0.3, 0.8) 0.15 176\n",
      "[100. 100. 100.] (0.3, 0.8) 0.16 177\n",
      "[100. 100. 100.] (0.3, 0.8) 0.17 178\n",
      "[100. 100. 100.] (0.3, 0.8) 0.18 179\n",
      "[100. 100. 100.] (0.3, 0.8) 0.19 180\n",
      "[100. 100. 100.] (0.3, 0.8) 0.2 181\n",
      "[100. 100. 100.] (0.3, 0.8) 0.21 182\n",
      "[100. 100. 100.] (0.3, 0.8) 0.22 183\n",
      "[100. 100. 100.] (0.3, 0.8) 0.23 184\n",
      "[100. 100. 100.] (0.3, 0.8) 0.24 185\n",
      "[100. 100. 100.] (0.3, 0.8) 0.25 186\n",
      "[100. 100. 100.] (0.3, 0.8) 0.26 187\n",
      "[100. 100. 100.] (0.3, 0.8) 0.27 188\n",
      "[100. 100. 100.] (0.3, 0.8) 0.28 189\n",
      "[100. 100. 100.] (0.3, 0.8) 0.29 190\n",
      "[100. 100. 100.] (0.3, 0.8) 0.3 191\n",
      "[100. 100. 100.] (0.3, 0.8) 0.31 192\n",
      "[100. 100. 100.] (0.3, 0.8) 0.32 193\n",
      "[100. 100. 100.] (0.3, 0.8) 0.33 194\n",
      "[100. 100. 100.] (0.3, 0.8) 0.34 195\n",
      "[100. 100. 100.] (0.3, 0.8) 0.35000000000000003 196\n",
      "[100. 100. 100.] (0.3, 0.8) 0.36 197\n",
      "[100. 100. 100.] (0.3, 0.8) 0.37 198\n",
      "[100. 100. 100.] (0.3, 0.8) 0.38 199\n",
      "[100. 100. 100.] (0.3, 0.8) 0.39 200\n",
      "[100. 100. 100.] (0.1, 0.9) 0.0 201\n",
      "[100. 100. 100.] (0.1, 0.9) 0.01 202\n",
      "[100. 100. 100.] (0.1, 0.9) 0.02 203\n",
      "[100. 100. 100.] (0.1, 0.9) 0.03 204\n",
      "[100. 100. 100.] (0.1, 0.9) 0.04 205\n",
      "[100. 100. 100.] (0.1, 0.9) 0.05 206\n",
      "[100. 100. 100.] (0.1, 0.9) 0.06 207\n",
      "[100. 100. 100.] (0.1, 0.9) 0.07 208\n",
      "[100. 100. 100.] (0.1, 0.9) 0.08 209\n",
      "[100. 100. 100.] (0.1, 0.9) 0.09 210\n",
      "[100. 100. 100.] (0.1, 0.9) 0.1 211\n",
      "[100. 100. 100.] (0.1, 0.9) 0.11 212\n",
      "[100. 100. 100.] (0.1, 0.9) 0.12 213\n",
      "[100. 100. 100.] (0.1, 0.9) 0.13 214\n",
      "[100. 100. 100.] (0.1, 0.9) 0.14 215\n",
      "[100. 100. 100.] (0.1, 0.9) 0.15 216\n",
      "[100. 100. 100.] (0.1, 0.9) 0.16 217\n",
      "[100. 100. 100.] (0.1, 0.9) 0.17 218\n",
      "[100. 100. 100.] (0.1, 0.9) 0.18 219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 100. 100.] (0.1, 0.9) 0.19 220\n",
      "[100. 100. 100.] (0.1, 0.9) 0.2 221\n",
      "[100. 100. 100.] (0.1, 0.9) 0.21 222\n",
      "[100. 100. 100.] (0.1, 0.9) 0.22 223\n",
      "[100. 100. 100.] (0.1, 0.9) 0.23 224\n",
      "[100. 100. 100.] (0.1, 0.9) 0.24 225\n",
      "[100. 100. 100.] (0.1, 0.9) 0.25 226\n",
      "[100. 100. 100.] (0.1, 0.9) 0.26 227\n",
      "[100. 100. 100.] (0.1, 0.9) 0.27 228\n",
      "[100. 100. 100.] (0.1, 0.9) 0.28 229\n",
      "[100. 100. 100.] (0.1, 0.9) 0.29 230\n",
      "[100. 100. 100.] (0.1, 0.9) 0.3 231\n",
      "[100. 100. 100.] (0.1, 0.9) 0.31 232\n",
      "[100. 100. 100.] (0.1, 0.9) 0.32 233\n",
      "[100. 100. 100.] (0.1, 0.9) 0.33 234\n",
      "[100. 100. 100.] (0.1, 0.9) 0.34 235\n",
      "[100. 100. 100.] (0.1, 0.9) 0.35000000000000003 236\n",
      "[100. 100. 100.] (0.1, 0.9) 0.36 237\n",
      "[100. 100. 100.] (0.1, 0.9) 0.37 238\n",
      "[100. 100. 100.] (0.1, 0.9) 0.38 239\n",
      "[100. 100. 100.] (0.1, 0.9) 0.39 240\n"
     ]
    }
   ],
   "source": [
    "#FIG 1\n",
    "\n",
    "#PARAMETERS\n",
    "lst_pq = [(0.3, 0.8), (0.1, 0.9)]\n",
    "lst_nn = [np.array([10., 10., 10.]), np.array([10., 20., 20.]), np.array([100., 100., 100.])]\n",
    "lst_rho = np.arange(0., 0.4, 0.01)\n",
    "\n",
    "#CHECK RULES-OF-THUMB\n",
    "for p, q in lst_pq:\n",
    "    for nn in lst_nn:\n",
    "        m = min(nn[:2])\n",
    "        ary_x = np.array([BB_pmf(1, k, 0.) for k in [p, q]])\n",
    "        z = np.array(list(reduce(np.convolve, ary_x)))\n",
    "        print ('n =', nn, 'p =', p, 'q =', q)\n",
    "        print ('ALL X_i PASS THE RULE-OF-THUMB:', all(np.ravel(m * ary_x) >= 1))\n",
    "        print ('Z PASSES THE RULE-OF-THUMB:', all(m * z >= 1), '\\n')\n",
    "\n",
    "#SIMULATIONS\n",
    "data = []\n",
    "i = 0\n",
    "for nb,nn in enumerate(lst_nn):\n",
    "    for npq,(p,q) in enumerate(lst_pq):\n",
    "        for nrho,rho in enumerate(lst_rho):\n",
    "            i += 1\n",
    "            print (nn, (p,q), rho, i)\n",
    "            if rho == 0:\n",
    "                label = path_csv + '_'.join([str(k) for k in [nn, p, q, rho]]) + '.csv'\n",
    "                row = run_simulations(p, q, rho, ranks, nn, alpha, n_repeats,\n",
    "                                      filename_pval_dist=label)\n",
    "            else:\n",
    "                row = run_simulations(p, q, rho, ranks, nn, alpha, n_repeats)\n",
    "            data.append(np.hstack([row, nn, [rho, p, q]]))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=data, columns=['Pgof', 'Ped']\n",
    "                       + ['Cgof_'+str(rk) for rk in ranks] + ['Ced_'+str(rk) for rk in ranks]\n",
    "                       + ['Zgof_'+str(rk) for rk in ranks] + ['Zed_'+str(rk) for rk in ranks]\n",
    "                       + ['n1', 'n2', 'n3', 'rho', 'X1_p', 'X2_q']\n",
    ")\n",
    "df.to_csv(path_csv+'Fig1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10. 10.] (0.3, 0.8) 0.0 1\n",
      "[25. 25. 25.] (0.3, 0.8) 0.0 2\n",
      "[50. 50. 50.] (0.3, 0.8) 0.0 3\n",
      "[75. 75. 75.] (0.3, 0.8) 0.0 4\n",
      "[100. 100. 100.] (0.3, 0.8) 0.0 5\n",
      "[250. 250. 250.] (0.3, 0.8) 0.0 6\n",
      "[500. 500. 500.] (0.3, 0.8) 0.0 7\n",
      "[750. 750. 750.] (0.3, 0.8) 0.0 8\n",
      "[1000. 1000. 1000.] (0.3, 0.8) 0.0 9\n",
      "[10. 20. 20.] (0.3, 0.8) 0.0 10\n",
      "[25. 50. 50.] (0.3, 0.8) 0.0 11\n",
      "[ 50. 100. 100.] (0.3, 0.8) 0.0 12\n",
      "[ 75. 150. 150.] (0.3, 0.8) 0.0 13\n",
      "[100. 200. 200.] (0.3, 0.8) 0.0 14\n",
      "[250. 500. 500.] (0.3, 0.8) 0.0 15\n",
      "[ 500. 1000. 1000.] (0.3, 0.8) 0.0 16\n",
      "[ 750. 1500. 1500.] (0.3, 0.8) 0.0 17\n",
      "[1000. 2000. 2000.] (0.3, 0.8) 0.0 18\n",
      "[10. 10. 10.] (0.3, 0.8) 0.25 19\n",
      "[25. 25. 25.] (0.3, 0.8) 0.25 20\n",
      "[50. 50. 50.] (0.3, 0.8) 0.25 21\n",
      "[75. 75. 75.] (0.3, 0.8) 0.25 22\n",
      "[100. 100. 100.] (0.3, 0.8) 0.25 23\n",
      "[250. 250. 250.] (0.3, 0.8) 0.25 24\n",
      "[500. 500. 500.] (0.3, 0.8) 0.25 25\n",
      "[750. 750. 750.] (0.3, 0.8) 0.25 26\n",
      "[1000. 1000. 1000.] (0.3, 0.8) 0.25 27\n",
      "[10. 20. 20.] (0.3, 0.8) 0.25 28\n",
      "[25. 50. 50.] (0.3, 0.8) 0.25 29\n",
      "[ 50. 100. 100.] (0.3, 0.8) 0.25 30\n",
      "[ 75. 150. 150.] (0.3, 0.8) 0.25 31\n",
      "[100. 200. 200.] (0.3, 0.8) 0.25 32\n",
      "[250. 500. 500.] (0.3, 0.8) 0.25 33\n",
      "[ 500. 1000. 1000.] (0.3, 0.8) 0.25 34\n",
      "[ 750. 1500. 1500.] (0.3, 0.8) 0.25 35\n",
      "[1000. 2000. 2000.] (0.3, 0.8) 0.25 36\n",
      "[10. 10. 10.] (0.1, 0.9) 0.0 37\n",
      "[25. 25. 25.] (0.1, 0.9) 0.0 38\n",
      "[50. 50. 50.] (0.1, 0.9) 0.0 39\n",
      "[75. 75. 75.] (0.1, 0.9) 0.0 40\n",
      "[100. 100. 100.] (0.1, 0.9) 0.0 41\n",
      "[250. 250. 250.] (0.1, 0.9) 0.0 42\n",
      "[500. 500. 500.] (0.1, 0.9) 0.0 43\n",
      "[750. 750. 750.] (0.1, 0.9) 0.0 44\n",
      "[1000. 1000. 1000.] (0.1, 0.9) 0.0 45\n",
      "[10. 20. 20.] (0.1, 0.9) 0.0 46\n",
      "[25. 50. 50.] (0.1, 0.9) 0.0 47\n",
      "[ 50. 100. 100.] (0.1, 0.9) 0.0 48\n",
      "[ 75. 150. 150.] (0.1, 0.9) 0.0 49\n",
      "[100. 200. 200.] (0.1, 0.9) 0.0 50\n",
      "[250. 500. 500.] (0.1, 0.9) 0.0 51\n",
      "[ 500. 1000. 1000.] (0.1, 0.9) 0.0 52\n",
      "[ 750. 1500. 1500.] (0.1, 0.9) 0.0 53\n",
      "[1000. 2000. 2000.] (0.1, 0.9) 0.0 54\n",
      "[10. 10. 10.] (0.1, 0.9) 0.25 55\n",
      "[25. 25. 25.] (0.1, 0.9) 0.25 56\n",
      "[50. 50. 50.] (0.1, 0.9) 0.25 57\n",
      "[75. 75. 75.] (0.1, 0.9) 0.25 58\n",
      "[100. 100. 100.] (0.1, 0.9) 0.25 59\n",
      "[250. 250. 250.] (0.1, 0.9) 0.25 60\n",
      "[500. 500. 500.] (0.1, 0.9) 0.25 61\n",
      "[750. 750. 750.] (0.1, 0.9) 0.25 62\n",
      "[1000. 1000. 1000.] (0.1, 0.9) 0.25 63\n",
      "[10. 20. 20.] (0.1, 0.9) 0.25 64\n",
      "[25. 50. 50.] (0.1, 0.9) 0.25 65\n",
      "[ 50. 100. 100.] (0.1, 0.9) 0.25 66\n",
      "[ 75. 150. 150.] (0.1, 0.9) 0.25 67\n",
      "[100. 200. 200.] (0.1, 0.9) 0.25 68\n",
      "[250. 500. 500.] (0.1, 0.9) 0.25 69\n",
      "[ 500. 1000. 1000.] (0.1, 0.9) 0.25 70\n",
      "[ 750. 1500. 1500.] (0.1, 0.9) 0.25 71\n",
      "[1000. 2000. 2000.] (0.1, 0.9) 0.25 72\n"
     ]
    }
   ],
   "source": [
    "#FIG 2\n",
    "\n",
    "#PARAMETERS\n",
    "lst_pq = [(0.3, 0.8), (0.1, 0.9)]\n",
    "lst_rho = np.array([0., 0.25])\n",
    "lst_n = np.array([10., 25., 50., 75., 100., 250., 500., 750., 1000.])\n",
    "base_nn = np.array([[1., 1., 1.], [1., 2., 2.]])\n",
    "\n",
    "#SIMULATIONS\n",
    "data = []\n",
    "i = 0\n",
    "for npq,(p,q) in enumerate(lst_pq):\n",
    "    for nrho,rho in enumerate(lst_rho):\n",
    "        for nb,base in enumerate(base_nn):\n",
    "            for n in lst_n:\n",
    "                nn = base * n\n",
    "                i += 1\n",
    "                print(nn, (p,q), rho, i)\n",
    "                row = run_simulations(p, q, rho, ranks, nn, alpha, n_repeats)\n",
    "                data.append(np.hstack([row, base, [rho, p, q, n]]))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=data, columns=['Pgof', 'Ped']\n",
    "                       + ['Cgof_'+str(rk) for rk in ranks] + ['Ced_'+str(rk) for rk in ranks]\n",
    "                       + ['Zgof_'+str(rk) for rk in ranks] + ['Zed_'+str(rk) for rk in ranks]\n",
    "                       + ['n1', 'n2', 'n3', 'rho', 'X1_p', 'X2_q', 'm']\n",
    ")\n",
    "df.to_csv(path_csv+'Fig2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10. 10.] (0.55, 0.8) 0.0 1\n",
      "[10. 10. 10.] (0.56, 0.8) 0.0 2\n",
      "[10. 10. 10.] (0.5700000000000001, 0.8) 0.0 3\n"
     ]
    }
   ],
   "source": [
    "#FIG 3\n",
    "\n",
    "#PARAMETERS\n",
    "q = 0.8\n",
    "lst_nn = [np.array([10., 10., 10.]), np.array([10., 20., 20.]), np.array([100., 100., 100.])]\n",
    "lst_rho = np.array([0., 0.25])\n",
    "#(p CLOSE TO q)\n",
    "lst_p_near = np.arange(0.55, 0.8, 0.01)\n",
    "#(p FAR FROM q)\n",
    "lst_p_far = np.arange(0.01, 0.251, 0.01)\n",
    "\n",
    "#SIMULATIONS\n",
    "data = []\n",
    "i = 0\n",
    "for nb,nn in enumerate(lst_nn):\n",
    "    for nrho,rho in enumerate(lst_rho):\n",
    "        for nlp,lst_p in enumerate([lst_p_near, lst_p_far]):\n",
    "            for npq,p in enumerate(lst_p):\n",
    "                i += 1\n",
    "                print(nn, (p,q), rho, i)\n",
    "                row = run_simulations(p, q, rho, ranks, nn, alpha, n_repeats)\n",
    "                if nlp == 0:\n",
    "                    data.append(np.hstack([row, nn, [rho, p, q, 'near']]))\n",
    "                else:\n",
    "                    data.append(np.hstack([row, nn, [rho, p, q, 'far']]))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=data, columns=['Pgof', 'Ped']\n",
    "                       + ['Cgof_'+str(rk) for rk in ranks] + ['Ced_'+str(rk) for rk in ranks]\n",
    "                       + ['Zgof_'+str(rk) for rk in ranks] + ['Zed_'+str(rk) for rk in ranks]\n",
    "                       + ['n1', 'n2', 'n3', 'rho', 'X1_p', 'X2_q', 'where_p']\n",
    ")\n",
    "df.to_csv(path_csv+'Fig3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
